{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP4_DL_2018_OptimDNN_Etus_Ronan.ipynb","provenance":[{"file_id":"1H-PWATIMBwBfot2gtKfzdetraBKGt6ns","timestamp":1544633929407}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vLSbN8DymegE"},"source":["# TP 4 - Deep Learning\n","# ECM 3A - UE IA - Option Digitale - 2018-2019"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fRkeE_P-DGPS","colab":{}},"source":["from __future__ import print_function"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZF_2BMMdd8JK","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"1c06c9ee-0968-4764-bf2a-d91c4c1f297e","executionInfo":{"status":"ok","timestamp":1571222042138,"user_tz":-120,"elapsed":44671,"user":{"displayName":"Thierry Artieres","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9VTz9U7MmNRd-CcgRnr8k0ciMj1P2QYbXyzv2zQ=s64","userId":"02018666546133225436"}}},"source":["### Pour utiliser sur google colab\n","\n","import os\n","\n","from google.colab import drive\n","drive.mount('drive')\n","\n","!mkdir -p drive -v\n","#!google-drive-ocamlfuse drive\n","\n","cwd = os.getcwd()\n","\n","#### Changez le chemin ci-dessous vers votre repertoire dans votre googledrive\n","##############################################################################\n","monchemin = 'drive/My Drive/IAAA/2018/DeepLearningCourse/Optim/Hyperas/'\n","##############################################################################\n","\n","dir_path  = os.path.join(cwd, monchemin)\n","dirs = os.listdir(dir_path)\n","os.chdir(dir_path)\n","\n","###  "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C7JJMzYamegG"},"source":["## 1. Comparaisons des algorithmes de gradient "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pnWABASVmegH"},"source":["###  Convnet pour la classification de Mnist"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7mEvn7plmegI"},"source":["#### Basics"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x2XScc1OmegK","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"39b935a0-cd45-47ac-803a-bb74aa3660a8","executionInfo":{"status":"ok","timestamp":1571222052571,"user_tz":-120,"elapsed":2348,"user":{"displayName":"Thierry Artieres","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9VTz9U7MmNRd-CcgRnr8k0ciMj1P2QYbXyzv2zQ=s64","userId":"02018666546133225436"}}},"source":["## Imports\n","\n","import keras\n","from keras.engine import Layer\n","from keras import backend as K\n","import numpy as np\n","from keras.legacy import interfaces\n","\n","from keras import metrics\n","\n","from keras import optimizers\n","from keras import regularizers\n","from keras.layers import Input, BatchNormalization, concatenate, Reshape, Conv2DTranspose, Activation\n","\n","from keras.layers import Input, Concatenate\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import Conv2D, UpSampling2D, MaxPooling2D\n","from keras.datasets import mnist\n","from keras.optimizers import Adam, Adagrad\n","from keras import backend as K\n","from keras import initializers\n","from keras.utils import np_utils\n","from keras import regularizers\n","\n","from keras import backend as K\n","\n","\n","from keras.datasets import mnist"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wu2Qj07amegN","colab":{}},"source":["\n","\n","def init_datas():\n","\t# input image dimensions\n","\timg_rows, img_cols = 28, 28\n","\tnb_classes = 10\n","\n","\t##### Chargement des donnees\n","\n","\t# the data, shuffled and split between train and test sets\n","\t(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","\n","\t\n","\tif 'tf' == 'th':\n","\t\tX_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n","\t\tX_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n","\t\tinput_shape = (1, img_rows, img_cols)\n","\telse:\n","\t\tX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","\t\tX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","\t\tinput_shape = (img_rows, img_cols, 1)\n","\n","\n","\tX_train = X_train.astype('float32')\n","\tX_test = X_test.astype('float32')\n","\tX_train = X_train /255\n","\tX_test = X_test /255\n","\tprint('X_train shape:', X_train.shape)\n","\tprint('X_test shape:', X_test.shape)\n","\tprint(X_train.shape[0], 'train samples')\n","\tprint(X_test.shape[0], 'test samples')\n","\n","\t# convert class vectors to binary class matrices\n","\ty_train = keras.utils.to_categorical(Y_train, nb_classes)\n","\ty_test = keras.utils.to_categorical(Y_test, nb_classes)\n","\tprint('y_train shape:', y_train.shape)\n","\tprint('y_test shape:', y_test.shape)\n","\n","\treturn X_train, y_train, X_test, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yVO5iGlVmegR","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"c688b27d-68f3-4f6d-dc33-cc859e093464","executionInfo":{"status":"ok","timestamp":1571222053602,"user_tz":-120,"elapsed":3371,"user":{"displayName":"Thierry Artieres","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9VTz9U7MmNRd-CcgRnr8k0ciMj1P2QYbXyzv2zQ=s64","userId":"02018666546133225436"}}},"source":["input_shape = (28, 28, 1)\n","\n","nb_classes =10 \n","X_train, Y_train, X_test, Y_test = init_datas()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","X_train shape: (60000, 28, 28, 1)\n","X_test shape: (10000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","y_train shape: (60000, 10)\n","y_test shape: (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JAM1UNqVbn9k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"202722b8-de37-4ddf-dd83-fccf07e4e530","executionInfo":{"status":"ok","timestamp":1571222053609,"user_tz":-120,"elapsed":3375,"user":{"displayName":"Thierry Artieres","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9VTz9U7MmNRd-CcgRnr8k0ciMj1P2QYbXyzv2zQ=s64","userId":"02018666546133225436"}}},"source":["print(X_train.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7RE7yCtwmegY","colab":{}},"source":["### Added 4 10 2018\n","def create_discri(opt= 'Adam'):\n","    d_input = Input(shape=(28, 28, 1) ,name=\"input\")\n","    x = Conv2D(64, kernel_size=(3, 3), activation='relu') (d_input)\n","    x = Conv2D(32, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = Dropout(0.25)(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    d_prediction = Dense(nb_classes, activation='softmax')(x)\n","    discriminatorC = Model(input = d_input, output = d_prediction)\n","    discriminatorC.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[metrics.categorical_accuracy])\n","    return discriminatorC\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8aCUQwqPvVo","colab_type":"text"},"source":["### To do \n","\n","Comparez les routines d'optimisation Adam, Adagrad, Adadelta etc en utiisant dfférents learning rates poru l'apprentissage des modèles défnis ci-dessus\n","\n","Vous tracerez deux figures, l'une pour l'accuracy, l'autre pour le loss, calculés sur le test set.\n","\n","Dans chaque figure vous ploitterez la quantité (Accuracy ou Loss) en fonction du learning rate en incluant une courbe par routine d'optimisation."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TnEeTSJRmego"},"source":["## Dropout"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4bLQpQpgmegi","colab":{}},"source":["### Added 4 10 2018\n","def create_discri(opt= 'Adam', DO_rate1=0.5, DO_rate2=0.5):\n","    d_input = Input(shape=(28, 28, 1) ,name=\"input\")\n","    x = Conv2D(64, kernel_size=(3, 3), activation='relu') (d_input)\n","    x = Conv2D(32, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = Dropout(DO_rate1)(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(DO_rate2)(x)\n","    d_prediction = Dense(nb_classes, activation='softmax')(x)\n","    discriminatorC = Model(input = d_input, output = d_prediction)\n","    discriminatorC.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[metrics.categorical_accuracy])\n","    return discriminatorC\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4q31Ampjmegk","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9e6689df-c866-4e15-8bbb-3ccf077d9f8a","executionInfo":{"status":"error","timestamp":1571222290094,"user_tz":-120,"elapsed":239846,"user":{"displayName":"Thierry Artieres","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9VTz9U7MmNRd-CcgRnr8k0ciMj1P2QYbXyzv2zQ=s64","userId":"02018666546133225436"}}},"source":["from keras.optimizers import Adam, Adagrad, Adadelta\n","\n","Perfs={}\n","T_DO1 = [0., 0.25, 0.5]\n","T_DO2 = [0., 0.25, 0.5]\n","\n","Optimizers = [\"Adam\", \"Adagrad\", \"Adadelta\"]\n","for opt in Optimizers:\n","    Perfs[opt]={}\n","    for do1 in T_DO1:\n","      for do2 in T_DO2:\n","        o = eval(opt)()\n","        D = create_discri(opt=o, DO_rate1 = do1 , DO_rate2 = do2)\n","        D.fit(X_train, Y_train, epochs=1)\n","        Perfs[opt][str(do1), str(do2)]=D.evaluate(X_test,Y_test)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/1\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","60000/60000 [==============================] - 27s 446us/step - loss: 0.1191 - categorical_accuracy: 0.9644\n","10000/10000 [==============================] - 1s 110us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 20s 339us/step - loss: 0.1435 - categorical_accuracy: 0.9567\n","10000/10000 [==============================] - 1s 115us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 20s 329us/step - loss: 0.1933 - categorical_accuracy: 0.9411\n","10000/10000 [==============================] - 1s 113us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 20s 330us/step - loss: 0.1227 - categorical_accuracy: 0.9614\n","10000/10000 [==============================] - 1s 115us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 21s 346us/step - loss: 0.1443 - categorical_accuracy: 0.9555\n","10000/10000 [==============================] - 1s 121us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 21s 343us/step - loss: 0.1994 - categorical_accuracy: 0.9386\n","10000/10000 [==============================] - 1s 134us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 21s 345us/step - loss: 0.1439 - categorical_accuracy: 0.9549\n","10000/10000 [==============================] - 1s 135us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 21s 350us/step - loss: 0.1754 - categorical_accuracy: 0.9459\n","10000/10000 [==============================] - 1s 132us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 22s 362us/step - loss: 0.2166 - categorical_accuracy: 0.9335\n","10000/10000 [==============================] - 1s 139us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","60000/60000 [==============================] - 19s 315us/step - loss: 0.1154 - categorical_accuracy: 0.9650\n","10000/10000 [==============================] - 1s 132us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","19392/60000 [========>.....................] - ETA: 14s - loss: 0.2781 - categorical_accuracy: 0.9162"],"name":"stdout"},{"output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-8-e3c0637713e5>\", line 14, in <module>\n","    D.fit(X_train, Y_train, epochs=1)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1178, in fit\n","    validation_freq=validation_freq)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 204, in fit_loop\n","    outs = fit_function(ins_batch)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n","    return self._call(inputs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n","    fetched = self._callable_fn(*array_vals)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n","    run_metadata_ptr)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 43, in <module>\n","    from tensorflow.contrib import cudnn_rnn\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/__init__.py\", line 38, in <module>\n","    from tensorflow.contrib.cudnn_rnn.python.layers import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/__init__.py\", line 38, in <module>\n","    from tensorflow.contrib.cudnn_rnn.python.layers import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/__init__.py\", line 23, in <module>\n","    from tensorflow.contrib.cudnn_rnn.python.layers.cudnn_rnn import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/cudnn_rnn.py\", line 20, in <module>\n","    from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 22, in <module>\n","    from tensorflow.contrib.rnn.python.ops import lstm_ops\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/__init__.py\", line 93, in <module>\n","    from tensorflow.contrib.rnn.python.ops.rnn_cell import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn_cell.py\", line 24, in <module>\n","    from tensorflow.contrib.layers.python.layers import layers\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/__init__.py\", line 116, in <module>\n","    from tensorflow.contrib.layers.python.layers import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/__init__.py\", line 33, in <module>\n","    from tensorflow.contrib.layers.python.layers.target_column import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/target_column.py\", line 24, in <module>\n","    from tensorflow.contrib.losses.python.losses import loss_ops\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/losses/__init__.py\", line 25, in <module>\n","    from tensorflow.contrib.losses.python import metric_learning\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/losses/python/metric_learning/__init__.py\", line 25, in <module>\n","    from tensorflow.contrib.losses.python.metric_learning.metric_loss_ops import *\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/losses/python/metric_learning/metric_loss_ops.py\", line 34, in <module>\n","    from sklearn import metrics\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/__init__.py\", line 7, in <module>\n","    from .ranking import auc\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\", line 35, in <module>\n","    from ..preprocessing import label_binarize\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/__init__.py\", line 6, in <module>\n","    from ._function_transformer import FunctionTransformer\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_function_transformer.py\", line 5, in <module>\n","    from ..utils.testing import assert_allclose_dense_sparse\n","  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/testing.py\", line 61, in <module>\n","    from nose.tools import raises as _nose_raises\n","  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 951, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 894, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1157, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1126, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1090, in _path_importer_cache\n","OSError: [Errno 107] Transport endpoint is not connected\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2339KMAumege","colab":{}},"source":["\n","\n","print (Perfs[\"Adam\"])\n","\n","print (Perfs[\"Adagrad\"])\n","\n","print (Perfs[\"Adadelta\"])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R8FVaeMDmego","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Pxt9PmWtmegs"},"source":["## Batch Normalization"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9BAXMarrmegv"},"source":["### To do \n","\n","1. Rajoutez une couche de BatchNormalization et expliquez le nombre de paramètres trainable et not trainable\n","\n","\n","2. Calculez les statistiques sur les activations moyennes (et les variances)  dans les différentes couches. Vous devez apprendre un réseau avec BN et un autre sans, puis faire passer les données d'apprentissage dans le réseau et extraire les prédiction sur les différentes couches cachées, puis afficher les valeurs moyennes d'activation sur les différentes couches \n","\n","NB: Le comportement de la couche de BN est plus visible avec des réseaux profonds non convolutionnels\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MSfz3K0Fmegw"},"source":["## Optimisation des hypermaramètres\n","\n","Quel que soit le problème, quelles que soient vos données, il existe un certain nombre d'hyper paramètres à régler pour apprndre un bon modèle (architceture du modèle, paramètres de l'algorithme d'optimisation etc).\n","\n","C'est l'objet du gridsearch, qui peut être exhaustif ou pas.\n","\n","Avant de vous lancer dans un gridsearch faites une estumation du temps que cela prendra."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M9jqf5d5megx"},"source":["### Gridsearch\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v1vcR7DVysay"},"source":["En utilisant un embedding des modèles dans sklearn et le gridsearchCV de sklearn"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nkqsTPoHmegy","colab":{}},"source":["from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M01i8Hyqmeg1","colab":{}},"source":["\n","\n","def create_discri_BN(optimizer='rmsprop', nb_filters1= 64,  nb_filters2= 32, fact = 'relu', nb_hid = 128, do_rate= 0.5, BN=False):\n","    d_input = Input(shape=(28, 28, 1) ,name=\"input\")\n","    x = Conv2D(nb_filters1, kernel_size=(3, 3), activation='relu') (d_input)\n","    x = Conv2D(nb_filters2, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    if BN :\n","      x = BatchNormalization()(x)\n","    x = Flatten()(x)\n","    x = Dense(nb_hid)(x)\n","    x = Activation(fact)(x)\n","    x = Dropout(do_rate)(x)\n","    d_prediction = Dense(nb_classes, activation='softmax')(x)\n","    discriminatorC = Model(input = d_input, output = d_prediction)\n","    discriminatorC.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n","    return discriminatorC\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCQRgYenyy6k","colab":{}},"source":["\n","model = KerasClassifier(build_fn=create_discri_BN)\n","\n","optimizers = ['rmsprop']\n","epochs = [10]\n","V_nb_hid = [64, 128]\n","DO_rate=[0, 0.25, 0.5]\n","\n","param_grid = dict(optimizer=optimizers,  nb_hid =V_nb_hid, do_rate= DO_rate)\n","\n","print (param_grid)\n","\n","grid = GridSearchCV(estimator=model, param_grid=param_grid)\n","grid_result = grid.fit(X_train, Y_train, epochs = 1, verbose=2)\n","# summarize results                                                                                                                                           \n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IsmqaTjlyzia"},"source":["Si vous utilisez un cluster de calcul, il est souvent plus simple \n","- De lancer un job par jeu d'hyperparametres\n","=> Boucles énumérant toutes les conbinaisons : Un job lancé à chaque fois\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0QWVeoXbyz06","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qbnIEkN4meg3"},"source":["### Optimisation Hyperas \n","Cf. https://conference.scipy.org/proceedings/scipy2013/pdfs/bergstra_hyperopt.pdf\n","Stratégie d'exploration partielle et informée de l'espace de recherche \n","\n","La méthode explore une partie de l'espace de recherche en construisant au fur et à mesure une mesure d'intérêt des différets paramètres à faire varier (voir l'article cité cidessus).\n","\n","Nb: Pour utiliser hyperas avec google colab votre notebook doit etre sauvegardé sur google colab et vous devez spécifier son chemin (voir cellule suivante).\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"65xwvdLpmeg5","colab":{}},"source":["\n","\n","!pip install hyperas\n","!pip install hyperopt\n","\n","from hyperopt import Trials, STATUS_OK, tpe\n","from keras.datasets import mnist\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","\n","from hyperas import optim\n","from hyperas.distributions import choice, uniform\n","\n","def init_datas():\n","    # input image dimensions\n","    img_rows, img_cols = 28, 28\n","    nb_classes = 10\n","\n","    ##### Chargement des donnees\n","\n","    # the data, shuffled and split between train and test sets\n","    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","    #X_train = X_train.reshape((X_train.shape[0],784))\n","    ###X_train = X_train.reshape(X_train.shape[0], 784) \n","    ###X_test = X_test.reshape(X_test.shape[0], 784)\n","    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","  \n","    X_train = X_train.astype('float32')\n","    X_test = X_test.astype('float32')\n","    X_train = X_train /255\n","    X_test = X_test /255\n","    print('X_train shape:', X_train.shape)\n","    print('X_test shape:', X_test.shape)\n","    print(X_train.shape[0], 'train samples')\n","    print(X_test.shape[0], 'test samples')\n","\n","    # convert class vectors to binary class matrices\n","    Y_train = keras.utils.to_categorical(Y_train, nb_classes)\n","    Y_test = keras.utils.to_categorical(Y_test, nb_classes)\n","    print('y_train shape:', Y_train.shape)\n","    print('y_test shape:', Y_test.shape)\n","\n","    return X_train, Y_train, X_test, Y_test\n","\n","\n","\n","def create_model(X_train, Y_train, X_test, Y_test):\n","   \n","    \"\"\"Model providing function:\n","\n","    Create Keras model with double curly brackets dropped-in as needed.\n","    Return value has to be a valid python dictionary with two customary keys:\n","        - loss: Specify a numeric evaluation metric to be minimized\n","        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n","    The last one is optional, though recommended, namely:\n","        - model: specify the model just created so that we can later use it again.\"\"\"\n"," \n","\n","    model = Sequential()\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n","    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout({{uniform(0, 1)}}))\n","    model.add(Flatten())\n","    model.add(Dense({{choice([64, 128, 256])}}))\n","    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n","    model.add(Dropout({{uniform(0, 1)}}))\n","\n","    # If we choose 'four', add an additional fourth layer\n","\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n","                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n","\n","    model.fit(X_train, Y_train,\n","              batch_size={{choice([64, 128])}},\n","              epochs=1,\n","              verbose=2,\n","              validation_data=(X_test, Y_test))\n","    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n","    print('Test accuracy:', acc)\n","    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n","\n","\n","init_datas()  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3qlIW15hmeg-","colab":{}},"source":["\n","\n","best_run, best_model = optim.minimize(model=create_model,\n","                                      data=init_datas2,\n","                                      algo=tpe.suggest,\n","                                      max_evals=5,\n","                                      trials=Trials(), \n","                                      notebook_name='TP4_DL_2018_OptimDNN_Etus')\n","X_train, Y_train, X_test, Y_test = init_datas2()\n","print(\"Evalutation of best performing model:\")\n","print(best_model.evaluate(X_test, Y_test))\n","print(\"Best performing model chosen hyper-parameters:\")\n","print(best_run)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Vhu1PzIq869F"},"source":["## To do : Régularisation et taille de l'ensemble d'apprentissage\n","\n","- Trouver la meilleure stratégie d'apprentissage pour une architcteure neuronale donnée, sur les données Mnist et pour des jeux de données limités. Vous utiliserez plusieurs tirages random pour chaque taille et calculerez des résultats moyennés. Vous utiliserez deux tailles de base d'apprentissage.\n","--  1000 données d'apprentissage en tout (environ 100 par classe)\n","-- 5000 données d'apprentissage en tout (environ 500) ? \n","\n","- Vous discuterez suit à vos résultats de l'intérêt de la régularisation dans le cas de données limitées et de l'Intérêt des différentes techniques de regularisation(dropout, pénalisation L1, L2)\n"]}]}