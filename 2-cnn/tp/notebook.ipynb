{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkkAFuMGsfou",
        "colab_type": "text"
      },
      "source": [
        "<h1>TP2 Deep Learning - CNN</h1>\n",
        "\n",
        "Cette troisiÃ¨me sÃ©ance porte sur la dÃ©couverte des rÃ©seaux de convolutions :\n",
        "* Retour sur MNIST\n",
        "* PremiÃ¨re architecture convolutionnelle\n",
        "* Visualisation des filtres\n",
        "* Utilisation de VGG16, un rÃ©seau prÃ©-entrainÃ©\n",
        "* Visualisation des filtres par maximisation des activations\n",
        "* Augmentation de donnÃ©es\n",
        "* Classification du jeu de donnÃ©es Cifar10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ua8jKmisfov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "venv_root = '/amuhome/ayache/deep'    # A modifier !! Utile seulement sur le serveur de Luminy\n",
        "\n",
        "import sys\n",
        "sys.path.append(venv_root+'/lib/python3.5/site-packages')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLtROamlsfo0",
        "colab_type": "text"
      },
      "source": [
        "Import des premiers packages nÃ©cessaires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDKhM0Dvsfo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_E-9SHIsfo9",
        "colab_type": "text"
      },
      "source": [
        "<h2> Chargement des donnÃ©es</h2>\n",
        "\n",
        "Ici on charge le jeu de donnÃ©es MNIST (les chiffres manuscrits), puis quelques instructions de mise en forme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0CEtl53sfo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols = 28, 28\n",
        "num_classes = 10\n",
        "nb_samples = len(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJuOtYO0sfpB",
        "colab_type": "text"
      },
      "source": [
        "Le jeu de donnÃ©es MNIST contient 60000 exemples rÃ©partis en 10 classes. Nous allons ici en sÃ©lectionner alÃ©atoirement un certain nombre pour accÃ©lÃ©rer les Ã©tapes suivantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-tQbYmjsfpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_idx = list(range(nb_samples))\n",
        "np.random.shuffle(l_idx) \n",
        "l_idx = l_idx[:10000]\n",
        "\n",
        "x_train, y_train = x_train[l_idx], y_train[l_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpt5ycb5sfpE",
        "colab_type": "text"
      },
      "source": [
        "Il est d'abord nÃ©cessaire de formater les vecteurs d'Ã©tiquettes en <i>one-hot vectors</i> de tailles num_classes. Ces vecteurs contiennent des 0 et un seul 1 par ligne Ã  l'indice correspondant Ã  la classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFAbfjdsfpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eGHETB7sfpI",
        "colab_type": "text"
      },
      "source": [
        "<h3> RÃ©seau \"Dense\"</h3>\n",
        "\n",
        "Reprenons le rÃ©seau considÃ©rÃ© Ã  la fin du premier TP. Notez son nombre de paramÃ¨tres et sa performance obtenue, ils nous serviront de rÃ©fÃ©rence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllXdJabsfpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=input_shape))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "loss = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1, callbacks=[], verbose=1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"score=\", score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-732BjGsfpL",
        "colab_type": "text"
      },
      "source": [
        "<h3>PremiÃ¨re architecture convolutionnelle</h3>\n",
        "\n",
        "CrÃ©ons un nouveau rÃ©seau dont les couches Dense (sauf la derniÃ¨re pour la classification) sont remplacÃ©es par des Conv2D, suivis de MaxPooling2D. Notons que la couche \"Flatten\" n'est pas utilisÃ©e en dÃ©but de rÃ©seau, puisque les donnÃ©es du rÃ©seau sont supposÃ©es 2D. En revanche, la couche Dense en bout de rÃ©seau suppose des donnÃ©es d'entrÃ©e en 1D.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPjwCntOv49R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model2.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PgZYoiGyKag",
        "colab_type": "text"
      },
      "source": [
        "<b>A faire :</b> Expliquez les nombres de paramÃ¨tres de chaque couche\n",
        "\n",
        "<h4>Entrainement du rÃ©seau :</h4>\n",
        "\n",
        "Appelons maintenant les fonctions fit et evaluate pour entrainer et tester le rÃ©seau. Visualisez la courbe d'apprentissage pour vÃ©rifier que tout s'apprend bien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2_ravRc0Fvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = model2.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1, callbacks=[], verbose=1)\n",
        "\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"score=\", score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq1pJA_i0VHm",
        "colab_type": "text"
      },
      "source": [
        "<h4>Visualisation des cartes</h4>\n",
        "\n",
        "Une carte \"rÃ©ponse\" (ou feature map) d'une couche de convolution correspond Ã  l'Ã©tat des activations en sortie d'une telle couche. Leur contenu dÃ©pend donc d'une image passÃ©e en entrÃ©e du rÃ©seau. \n",
        "\n",
        "Une couche dÃ©finie pour apprendre 64 filtres de convolution, gÃ©nÃ¨re ainsi 64 cartes. On dÃ©finie d'abord une fonction pour l'affichage d'un tableau d'images (via matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFe_Le1A71sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_images(images, cols = 1):\n",
        "    \n",
        "    n_images = len(images)\n",
        "    fig = plt.figure()\n",
        "    for n, image in enumerate(images):\n",
        "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
        "        plt.axis('off')\n",
        "        if image.ndim == 2:\n",
        "            plt.gray()\n",
        "        plt.imshow(image)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyLX83L1A8oA",
        "colab_type": "text"
      },
      "source": [
        "Une maniÃ¨re simple pour obtenir ces cartes, via l'API Keras, consiste Ã  faire passer une image (au choix mais de la bonne taille) Ã  travers un rÃ©seau tronquÃ© Ã  la couche dont on veut visualiser les sorties."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxwKrb9G0UqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "# DÃ©finition d'un modÃ¨le via la \"graph\" API de Keras\n",
        "model_tmp = Model(model2.layers[0].input, model2.layers[0].output)\n",
        "\n",
        "# Cartes rÃ©ponses de x_test[10] (un '0')\n",
        "feature_maps = model_tmp.predict(np.expand_dims(x_test[10], 0))\n",
        "\n",
        "# normalisation des valeurs entre 0 et 1\n",
        "minimum, maximum = np.min(feature_maps), np.max(feature_maps)\n",
        "feature_maps = (feature_maps - minimum) / (maximum - minimum)\n",
        "\n",
        "print(minimum, maximum, feature_maps.shape)\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "images = []\n",
        "for i in range(64):\n",
        "  images.append(np.array(255*feature_maps[:,:,:,i]).reshape(28,28).astype('uint8'))\n",
        "\n",
        "show_images(images, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I0Sk3WWKhci",
        "colab_type": "text"
      },
      "source": [
        "Les images obtenues semblent montrer que les filtres appris dans la premiÃ¨re couche du rÃ©seau permettent la dÃ©tection d'orientations ou des contours. \n",
        "\n",
        "\n",
        "\n",
        "<h4>Visualisation des filtres</h4>\n",
        "\n",
        "La visualisation des filtres de la couche d'entrÃ©e est relativement immÃ©diate puisque que les filtres ont le mÃªme nombre de channels que les donnÃ©es d'entrÃ©e. Autrement dit, les filtres de la premiÃ¨re couche sont dÃ©finis sur le mÃªme domaine que les donnÃ©es.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YMjW4AT-HWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RÃ©cupÃ¨re tous les paramÃ¨tres appris par le rÃ©seau\n",
        "weights = model2.get_weights()\n",
        "\n",
        "for w in weights: print(w.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqAT1-YRMuGL",
        "colab_type": "text"
      },
      "source": [
        "<b>A faire : </b> A quoi correspondent chaque ligne issues de l'affichage de la cellule prÃ©cÃ©dente ?\n",
        "\n",
        "Affichons maintenant les filtres de la premiÃ¨re couche de convolution :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Us2w4-M5YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize values between 0 and 1\n",
        "minimum, maximum = np.min(weights[0]), np.max(weights[0])\n",
        "weights0 = (weights[0] - minimum) / (maximum - minimum)\n",
        "\n",
        "print(minimum, maximum)\n",
        "# entre 0 et 255 pour l'affichage\n",
        "weights0 *= 255.\n",
        "\n",
        "images = []\n",
        "for i in range(64):\n",
        "  images.append(np.array(255*weights0[:,:,:,i]).reshape(5,5).astype('uint8'))\n",
        "\n",
        "show_images(images, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrEXlY3pTI3E",
        "colab_type": "text"
      },
      "source": [
        "<h3> CNN pour des images naturelles </h3>\n",
        "\n",
        "Les filtres de convolutions appris sur les donnÃ©es MNIST ne sont pas trÃ¨s parlantes, intÃ©ressons nous plutÃ´t Ã  un rÃ©seau (beaucoup plus profond) adaptÃ© Ã  la classification d'images naturelles. Nous allons considÃ©rer pour cela le rÃ©seau VGG16, prÃ©-entrainÃ© sur le dataset ImageNet (cf cours)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVuyJhICTIIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pageperso.lis-lab.fr/stephane.ayache/cat.jpg\n",
        "!wget https://pageperso.lis-lab.fr/stephane.ayache/imagenet_class_index.json \n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import json\n",
        "\n",
        "# RÃ©cupÃ©ration du modÃ¨le complet VGG16\n",
        "model3 = VGG16(include_top=True, weights='imagenet')\n",
        "#print(model3.summary())\n",
        "\n",
        "# chargement d'un dictionnaire qui met en correspondant l'index d'une classe ImageNet et son nom\n",
        "with open('imagenet_class_index.json') as f:\n",
        "    CLASS_INDEX = json.load(f)\n",
        "\n",
        "# chargement et preprocess de l'image (dont normalisation et redimensionnement)\n",
        "img_path = 'cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# prÃ©diction et affichage de la classe de probabilitÃ© maximale\n",
        "softmax_output = model3.predict(x)\n",
        "best_class = np.argmax(softmax_output)\n",
        "im_class = CLASS_INDEX[str(best_class)][1]\n",
        "print(\"prediction: \", im_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy49stywZY7Y",
        "colab_type": "text"
      },
      "source": [
        "Notre chaton a Ã©tÃ© reconnu comme un chat ? Alors tout va bien, et regardons les filtres de la premiÃ¨re couche ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV8fKj8naJhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = model3.get_weights()\n",
        "#for w in weights: print(w.shape)\n",
        "  \n",
        "# normalize values between 0 and 1\n",
        "minimum, maximum = np.min(weights[0]), np.max(weights[0])\n",
        "weights0 = (weights[0] - minimum) / (maximum - minimum)\n",
        "\n",
        "print(minimum, maximum)\n",
        "# entre 0 et 255 pour l'affichage\n",
        "weights0 *= 255.\n",
        "\n",
        "images = []\n",
        "for i in range(64):\n",
        "  images.append(np.array(255*weights0[:,:,:,i]).reshape(3,3,3).astype('uint8'))\n",
        "\n",
        "show_images(images, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqUT5x04cjnm",
        "colab_type": "text"
      },
      "source": [
        "Notez qu'on affiche ici les fltres en RGB alors qu'on pourrait les afficher en sÃ©parant les channels. Dans tous les cas, cette visualisation reste peu informative, pour mieux comprendre le rÃ´le d'une couche de convolution, d'autres mÃ©thodes sont plus efficaces (cf cours prÃ©cÃ©dent). Ci dessous, nous allons gÃ©nÃ©rer une image qui maximise la valeur d'une carte d'activation (rÃ©ponse Ã  un filtre).\n",
        "\n",
        "<h3> Visualisation par maximisation d'activations</h3>\n",
        "  \n",
        "Les fonctions Tensorflow du backend Keras nous permettent de dÃ©finir une fonction d'une image vers les activations d'une carte d'une couche de convolution. Maximiser cette fonction en suivant le gradient de la sortie par rapport aux entrÃ©es, revient Ã  dÃ©terminer une image (artificielle) dont VGG16 obtient une forte rÃ©ponse Ã  la convolution du filtre ciblÃ©. L'image produite va Ãªtre composÃ©e du \"pattern\" reconnu par le filtre...\n",
        "\n",
        "D'abord, quelques fonctions utiles :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nizHh4DMeC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deprocess_image(x):\n",
        "# normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + K.epsilon())\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    \n",
        "    return x * 255.\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
        "  \n",
        "\n",
        "print(model3.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEB1Sk5QvcB",
        "colab_type": "text"
      },
      "source": [
        "DÃ©finition d'une fonction en Keras ; obtention du gradient ; gradient ascent pour maximiser ; "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD1QKInV7iA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "num_filter = 208\n",
        "\n",
        "# entrÃ©e de la fonction Ã  maximiser = entrÃ©e du rÃ©seau VGG = une image\n",
        "input_img = model3.layers[0].input\n",
        "\n",
        "# sortie = Somme (moyenne) des activations d'une carte de convolution associÃ©e au filtre num_filter\n",
        "output = K.mean(model3.layers[17].output[:, :, :, num_filter])\n",
        "\n",
        "# returns the gradients of output w.r.t. input\n",
        "grads = K.gradients(output, input_img)[0]\n",
        "grads = normalize(grads)\n",
        "\n",
        "# fonction : input -> output, gradients \n",
        "func = K.function([input_img], [output, grads])\n",
        "\n",
        "## gradient ascent ##\n",
        "\n",
        "# point de dÃ©part alÃ©atoire\n",
        "x = np.random.random((1, 224, 224, 3)) * 255.\n",
        "x = preprocess_input(x)\n",
        "\n",
        "for i in range(40): # 40 iterations\n",
        "    loss_value, grads_value = func([x])\n",
        "    x += grads_value * 10\n",
        "\n",
        "    print('Current loss value:', loss_value)\n",
        "    if loss_value <= 0.:\n",
        "        # some filters get stuck to 0\n",
        "        break\n",
        "\n",
        "# point d'arrivÃ©e : conversion en RGB puis affichage\n",
        "xx = deprocess_image(x)\n",
        "\n",
        "from PIL import Image\n",
        "print(xx.shape)\n",
        "display(Image.fromarray(xx[0].astype('uint8')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCkmkql8ahOv",
        "colab_type": "text"
      },
      "source": [
        "<b> A faire : </b> variez les couches et les filtres, puis commentez vos rÃ©sultats obtenus. Comment obtenir des motifs encore plus complexes ?\n",
        "\n",
        "<h2> Entrainement d'un rÃ©seau trÃ¨s profond </h2>\n",
        "\n",
        "Un rÃ©seau trÃ¨s profond tel que VGG contient Ã©normÃ©ment de paramÃ¨tres, son entrainement peu s'avÃ©rer compliquer. Tous les paramÃ¨tres doivent entrer en mÃ©moire (RAM ou GPU), ainsi que toutes les donnÃ©es d'un minibatch. Dans le cas d'images relativement volumineuses (ie: Imagenet =255x255x3), la taille du minibatch est souvent ainsi trÃ¨s couteux en mÃ©moire et se voit ainsi rÃ©duit Ã  quelques images, rendant l'entrainement encore plus long... \n",
        "\n",
        "Souvent, de grandes bases de donnÃ©es ne sont pas disponibles. Dans ce cas, pour parvenir Ã  entrainer un tel rÃ©seau avec peu d'images, plusieurs options sont possibles :\n",
        "- partir d'un rÃ©seau dÃ©jÃ  (prÃ©-)entrainÃ©, et/ou utiliser ses poids pour initialiser un autre rÃ©seau qui sera appris sur une base (rÃ©duite) d'images (= finetuning, trÃ¨s efficace)\n",
        "- rÃ©gulariser les poids du rÃ©seau (peut aider mais ne suffit pas)\n",
        "- augmenter artificiellement le nombre de donnÃ©es (amÃ©liore toujours les performances d'un rÃ©seau)\n",
        "\n",
        "Dans la suite, nous illustrons ce dernier point sur les donnÃ©es MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWqj7Jafn4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols = 28, 28\n",
        "num_classes = 10\n",
        "nb_samples = len(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# SÃ©lection alÃ©atoire de 5000 exemples\n",
        "l_idx = list(range(nb_samples))\n",
        "np.random.shuffle(l_idx) \n",
        "l_idx = l_idx[:5000]\n",
        "x_train, y_train = x_train[l_idx], y_train[l_idx]\n",
        "\n",
        "# conversion des Ã©tiquettes au format one-hot vector\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Architecture du modÃ¨le\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#print(model2.summary())\n",
        "\n",
        "model2.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1)\n",
        "\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"score=\", score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UyYs5MIy9gJ",
        "colab_type": "text"
      },
      "source": [
        "La performance obtenue peut Ãªtre amÃ©liorÃ©e en augmentant les donnÃ©es. La cellule suivante gÃ©nÃ¨re 20000 donnÃ©es Ã  partir des 5000 utilisÃ©es jusque lÃ .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNiXpD4ay-Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# dÃ©claration d'un gÃ©nÃ©rateur, qui transformera \"Ã  la volÃ©e\" des donnÃ©es MNIST \n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=10,\n",
        "    zoom_range = 0.05, \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=False, # flip horizontal et vertical n'ont pas de sens pour des digits !\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# On instancie le gÃ©nÃ©rateur\n",
        "flow = datagen.flow(x_train, y_train, batch_size=128, shuffle=True)\n",
        "\n",
        "# Pour affichage : une itÃ©ration du gÃ©nÃ©rateur\n",
        "xx = next(flow)\n",
        "print(xx[0].shape, xx[1].shape)\n",
        "\n",
        "images = []\n",
        "for i in range(64):\n",
        "  images.append(np.array(255*xx[0][i,:,:,:]).reshape(28,28).astype('uint8'))\n",
        "show_images(images, 8)\n",
        "\n",
        "\n",
        "# rÃ©initialisation du modÃ¨le\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# entrainement avec les donnÃ©es augmentÃ©es (Ã  la volÃ©e)\n",
        "model2.fit_generator(datagen.flow(x_train, y_train, batch_size=128), steps_per_epoch=int(20000/128), epochs=20)\n",
        "\n",
        "# Ã©valuation\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"score=\", score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MCbzBFfFwcf",
        "colab_type": "text"
      },
      "source": [
        "<b>A faire : </b> testez d'autres formes d'augmentation et d'autres quantitÃ©s pour constater l'impact sur la prÃ©cision du rÃ©seau.\n",
        "<b>A faire : </b> modifiez l'architecture pour la classification d'images naturelles, en utilisant le jeu de donnÃ©es Cifar10."
      ]
    }
  ]
}
